{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humans are good at recognizing patterns. When we're kids, our parents teach us concepts by pointing at things and calling them names. Eventually, we learn to generalize, learning what a cup is, learning what a chair is, and so on.\n",
    "\n",
    "This hands-on exercise will explore how learning happens when we're given new things and their labels. We'll learn some new concepts we've never seen before to remember how learning happens.\n",
    "\n",
    "We'll gain an intuitive understanding about the following concepts:\n",
    "\n",
    "- training sets\n",
    "- testing sets\n",
    "- labels\n",
    "- over-fitting\n",
    "\n",
    "\n",
    "# Activity (20 min)\n",
    "\n",
    "You are given a 5 scripted characters in a different language (e.g. Farsi), and their label in English on the back. Study them.\n",
    "\n",
    "Now, you're given a new character, but there's no label on the back. Is it one of the ones you've already seen? If so, which? What you've just done is found its \"nearest neighbour\". This is a form of classification, which we'll talk about later.\n",
    "\n",
    "Now it's time for a test! More specifically, a test set. Classify 10 new, unlabeled characters based on the 5 labeled examples you've seen. Some of them may be \"other\". Is it hard? How accurate are you?\n",
    "\n",
    "In general, it can be hard to learn from such few examples (only 1 of each!), especially when some of the characters look very different (e.g. various fonts). So, we need to increase the size of your training set. \n",
    "\n",
    "## Better Learning\n",
    "\n",
    "You are now given 5 more labeled examples per character, bringing your training set to a total of 6 examples x 5 characters = 30 examples. Study them.\n",
    "\n",
    "As a test, you're given 10 more unlabeled characters to classify. Does your accuracy increase? Is it easier/faster?\n",
    "\n",
    "What you experienced when your training set was small was called \"overfitting\". The \"model\" or representation of the characters in your head was overly specific to the example you saw. Can you think of another example of overfitting in real life? (e.g. kids thinking that all 4-legged animals are \"dogs\").\n",
    "\n",
    "When you increased the size of your dataset, you were able to have a better \"model\" of each character, and avoid overfitting.\n",
    "\n",
    "# Supervised Learning\n",
    "\n",
    "In machine learning, we call this kind of learning \"supervised learning\" because we have a teacher that provides labels (aka groundtruth). This is opposed to unsupervised learning where there are no labels, which we'll talk about later.\n",
    "\n",
    "# Quiz (15 min)\n",
    "\n",
    "- What is a training set, and what is it used for? Can you give an example of a training set in real life?\n",
    "\n",
    "- What is a test set, and what is it used for? Can you give an example of a test set in real life? \n",
    "\n",
    "- True or false: Labels are symbolic representations of data.\n",
    "    \n",
    "- Describe the problem of over-fitting, and how we can resolve it.\n",
    "\n",
    "Bonus: Think about how we learn in school. What does a test reveal?\n",
    "\n",
    "# AI Ethics Reflections\n",
    "\n",
    "Who labeled the data? Were they experts? Was there enough data? Were the training and testing sets well-balanced?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
